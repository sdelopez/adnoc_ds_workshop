{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, you will be given imbalanced datasets, where there will be more instances of class 1 than class 2. To avoid the imbalance negatively affecting performance, it is important to even out the data. This can be done by randomly undersampling the majority class, or oversampling the minority class.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "0  1   5   6\n",
       "1  1   4   4\n",
       "2  1   4   5\n",
       "3  2   7   8\n",
       "4  1   8   7\n",
       "5  1   5   7\n",
       "6  2   4   2\n",
       "7  1   2   6\n",
       "8  1   7   5\n",
       "9  1   2   9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(columns=[\"y\",\"x1\", \"x2\"], data=[[1,5,6],[1,4,4],[1,4,5],\n",
    "                                                    [2,7,8],[1,8,7], [1,5,7],\n",
    "                                                    [2,4,2],[1,2,6], [1,7,5],\n",
    "                                                    [1,2,9]\n",
    "                                                   ])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "  If this breaks, you might need to load a package...\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are more of instances of 1's than 2's. Although the imbalance is easily visible in this dataset, it won't be in real life cases. Count and save class occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 8\n",
      "Class 2: 2\n"
     ]
    }
   ],
   "source": [
    "count_class_1, count_class_2 = data.y.value_counts()\n",
    "\n",
    "print('Class 1:', count_class_1)\n",
    "\n",
    "print('Class 2:', count_class_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "Check out the [value_counts](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html) method !\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "data.y.value_counts()\n",
    "``` should do the trick !\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset according to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class_1 = data[data['y']==1]\n",
    "\n",
    "data_class_2 = data[data['y']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "0  1   5   6\n",
       "1  1   4   4\n",
       "2  1   4   5\n",
       "4  1   8   7\n",
       "5  1   5   7\n",
       "7  1   2   6\n",
       "8  1   7   5\n",
       "9  1   2   9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "3  2   7   8\n",
       "6  2   4   2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "Maybe filter your dataframe based on the class value ?\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "data_class_1 = data[data['y'] == 1]\n",
    "data_class_2 = data[data['y'] == 2]\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling will downsize the majority class to the number of occurences in the minority class by random selection.\n",
    "\n",
    "Use pandas' sample() method to sample from class 1 the same number of occurences as in class 2. Then, concatenate the undersampled class 1 data with the original class 2 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y     8\n",
       "x1    8\n",
       "x2    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class_1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "9  1   2   9\n",
       "2  1   4   5\n",
       "3  2   7   8\n",
       "6  2   4   2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_under = data_class_1.sample(n=data_class_2.count()['y'], random_state=1)\n",
    "\n",
    "df_balanced_under = pd.concat([df_class_1_under, data_class_2])\n",
    "\n",
    "df_balanced_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "The following pandas methods will be useful: `sample` and `concat`.\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "data_class_1_under = data_class_1.sample(count_class_2)\n",
    "data_balanced_under = pd.concat([data_class_1_under, data_class_2], axis=0)\n",
    "data_balanced_under\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling will upsize the minority class to the number of occurences in the majority class by random duplication.\n",
    "\n",
    "Go ahead, oversample and concatenate! Because you will add instances, the sample() method requires a specific parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "0  1   5   6\n",
       "1  1   4   4\n",
       "2  1   4   5\n",
       "4  1   8   7\n",
       "5  1   5   7\n",
       "7  1   2   6\n",
       "8  1   7   5\n",
       "9  1   2   9\n",
       "6  2   4   2\n",
       "6  2   4   2\n",
       "6  2   4   2\n",
       "3  2   7   8\n",
       "6  2   4   2\n",
       "6  2   4   2\n",
       "3  2   7   8\n",
       "6  2   4   2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_2_over = data_class_2.sample(n=data_class_1.count()['y'], replace=True)\n",
    "\n",
    "df_balanced_over = pd.concat([data_class_1, df_class_2_over])\n",
    "\n",
    "df_balanced_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  x1  x2\n",
       "6  2   4   2\n",
       "3  2   7   8\n",
       "6  2   4   2\n",
       "3  2   7   8\n",
       "3  2   7   8\n",
       "3  2   7   8\n",
       "3  2   7   8\n",
       "6  2   4   2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_2_over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "Make use of `sample` and `concat` as well !\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "data_class_2_over = data_class_2.sample(count_class_1, replace=True)\n",
    "data_balanced_over = pd.concat([data_class_1, data_class_2_over], axis=0)\n",
    "data_balanced_over\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning algorithms such as SVMs assume that all features have a somewhat normal distribution, centered around zero and a similar variance. However, that is rarely the case in wild datasets. A feature that has a significantly larger variance might dominate others and prevent the model to learn from them. \n",
    "\n",
    "Standaridization transforms each feature by removing its mean value (u) and dividing it by its standard deviation (s). As such, it is centered at zero.\n",
    "\n",
    "z = (x - u) / s\n",
    "\n",
    "Standardization can be done using Sklearn's \"preprocessing\" package and its method \"StandardScaler\". \n",
    "\n",
    "- Initiate default Scaler\n",
    "- Fit data\n",
    "- Transform data\n",
    "- Print scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[1. 1.]\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[0,0],\n",
    "        [1,1],\n",
    "        [2,2]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.mean_)\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "If you don't know the syntax, check out the documentation !\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = [[0,0],\n",
    "        [1,1],\n",
    "        [2,2]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "scaled_data = scaler.transform(data)\n",
    "scaled_data\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scaler is now stored in memory and can reproduce the equivalent transformation on new data. Transform the new data to verify it does the right transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "new_data = [[1,1]]\n",
    "\n",
    "print(scaler.transform(new_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "new_data = [[1,1]]\n",
    "scaler.transform(new_data)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling to range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another transformation option is to scale to a range. The advantage of this method is its resistance to very small standard deviations. It also preserves zero entries in sparse datasets. There are two ways to scale to a range in Sklearn:\n",
    "\n",
    "- MinMaxScaler transforms to a range [0,1]\n",
    "- MaxAbsScaler transforms to a range [-1,1]\n",
    "\n",
    "Below, use MinMaxScaler to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "[[0.  0. ]\n",
      " [0.5 0.5]\n",
      " [1.  1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[0,0],\n",
    "        [1,1],\n",
    "        [2,2]]\n",
    "\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "print(mmscaler.fit(data))\n",
    "print(mmscaler.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "    \n",
    "    You know it: documentation 😃 ! \n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = [[0,0],\n",
    "        [1,1],\n",
    "        [2,2]]\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "min_max_scaler.fit(data)\n",
    "\n",
    "min_max_scaled_data = min_max_scaler.transform(data)\n",
    "\n",
    "min_max_scaled_data\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxAbsScaler works the same way but transforms the data to a range [-1,1]. That transformation is better suited to data already centered at zero (standardized).\n",
    "\n",
    "Below, standardize the data before scaling it in the range [-1,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[[-1.22474487 -1.22474487]\n",
      " [ 0.          0.        ]\n",
      " [ 1.22474487  1.22474487]]\n",
      "MaxAbsScaler(copy=True)\n",
      "[[-1. -1.]\n",
      " [ 0.  0.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "data = [[-1,-1],\n",
    "        [1,1],\n",
    "        [3,3]]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(data))\n",
    "std_data = scaler.transform(data)\n",
    "print(std_data)\n",
    "\n",
    "mascaler = MaxAbsScaler()\n",
    "print(mascaler.fit(std_data))\n",
    "print(mascaler.transform(std_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "    \n",
    "    No other option than checking the documentation 😃\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "data = [[-1,-1],\n",
    "        [1,1],\n",
    "        [3,3]]\n",
    "\n",
    "standardizer = StandardScaler()\n",
    "standardizer.fit(data)\n",
    "standardized_data = standardizer.transform(data)\n",
    "\n",
    "max_abs_scaler = MaxAbsScaler()\n",
    "max_abs_scaler.fit(standardized_data)\n",
    "max_abs_scaled_data = max_abs_scaler.transform(standardized_data)\n",
    "\n",
    "max_abs_scaled_data\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the presence of outliers, standard scaling would not support the abnormally extreme data points. Sklearn's RobustScaler offers a more robust solution for such datasets.\n",
    "\n",
    "Instead of removing the mean which would be affected by the outliers, it focuses on the median. It then scales the data according to the Interquartile Range (IQR). \n",
    "\n",
    "If the data was to be split into 4 quarters, the IQR represents the 2nd and 3rd quarters. By excluding the outermost quarters(1st and 4th), the algorithm intends to exclude the outliers.\n",
    "\n",
    "RobustScaler uses the IQR by default but the range can be set manually.\n",
    "\n",
    "Use RobustScaler to transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "[2. 2.]\n",
      "[[-1.         -0.00200401]\n",
      " [ 0.          0.        ]\n",
      " [ 1.          1.99799599]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = [[1,1],\n",
    "        [2,2],\n",
    "        [3,999]]\n",
    "\n",
    "rscaler = RobustScaler()\n",
    "rscaler.fit(data)\n",
    "print(rscaler)\n",
    "print(rscaler.center_)\n",
    "r_data = rscaler.transform(data)\n",
    "print(r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "    \n",
    "By repeating the same hint over and over it's not even a hint anymore 😃 ! Look at this [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html)\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "data = [[1,1],\n",
    "        [2,2],\n",
    "        [3,999]]\n",
    "r_scaler = RobustScaler()\n",
    "r_scaler.fit(data)\n",
    "r_scaler.transform(data)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same thing but set a manual range to exclude the extreme fifths of the dataset. What is the transformed value of the outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2.]\n",
      "[[-0.83333333 -0.00167001]\n",
      " [ 0.          0.        ]\n",
      " [ 0.83333333  1.66499666]]\n"
     ]
    }
   ],
   "source": [
    "quantile_range=(25.0, 75.0)\n",
    "\n",
    "data = [[1,1],\n",
    "        [2,2],\n",
    "        [3,999]]\n",
    "\n",
    "rscaler2 = RobustScaler(copy=True, quantile_range=(20.0, 80.0), with_centering=True, with_scaling=True)\n",
    "rscaler2.fit(data)\n",
    "print(rscaler2.center_)\n",
    "r_data2 = rscaler2.transform(data)\n",
    "print(r_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "manual_r_scaler = RobustScaler(quantile_range=(20.0,80.0))\n",
    "manual_r_scaler.fit(data)\n",
    "manual_r_scaler.transform(data)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target features\n",
       "0      a        u\n",
       "1      b        s\n",
       "2      a        s\n",
       "3      c        r"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=[\"target\", \"features\"], \n",
    "                  data=[[\"a\",\"u\"],[\"b\",\"s\"],[\"a\",\"s\"],[\"c\",\"r\"]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain cases, targets and/or features will be letters. Before training a Machine Learning algorithm, you will need to convert them to numbers.\n",
    "\n",
    "When dealing with the targets, you can use Sklearn's LabelEncoder. Do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target features\n",
       "0       0        u\n",
       "1       1        s\n",
       "2       0        s\n",
       "3       2        r"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_target = LabelEncoder()\n",
    "le_target.fit(df['target'])\n",
    "list(le_target.classes_)\n",
    "df['target']=le_target.transform(df['target'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "[This one](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) is important to know !    \n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "target_encoded = le.fit_transform(df['target'])\n",
    "target_encoded\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same could be executed on the features, but it may negatively affect the accuracy of the classifier. \n",
    "\n",
    "Taking the example of our dataframe, [u,s,s,r] could be transformed to [1,2,2,3]. A Machine Learning algorithm could wrongly consider that 1 and 3 are more distant from one another than 1 and 2, take that into consideration, and create an unwanted distortion.\n",
    "\n",
    "To avoid such phenomenon, it is better to create multiple binary features. This can be done with pandas' get_dummies. Use it to transform the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   r  s  u\n",
       "0  0  0  1\n",
       "1  0  1  0\n",
       "2  0  1  0\n",
       "3  1  0  0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_encoded = pd.get_dummies(df['features'])\n",
    "\n",
    "feature_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "Check out [this page](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "feature_encoded = pd.get_dummies(df.features)\n",
    "feature_encoded\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binning is the process of turning continuous data into discrete data according to sections (bins). For example, in a dataset constituted of people's ages, you may want to consider age groups.\n",
    "\n",
    "Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age\n",
       "0   13\n",
       "1   15\n",
       "2   18\n",
       "3   19\n",
       "4   20\n",
       "5   22\n",
       "6   23\n",
       "7   23"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = pd.DataFrame(columns=[\"age\"], \n",
    "                  data=([[13],[15],[18],[19],[20],[22],[23],[23]]))\n",
    "\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To part the data, you can use panda's \"cut\". Use it to cut the following age data into two bins \"teens\" and \"adults\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>Teen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  group\n",
       "0   13   Teen\n",
       "1   15   Teen\n",
       "2   18   Teen\n",
       "3   19   Teen\n",
       "4   20   Teen\n",
       "5   22  Adult\n",
       "6   23  Adult\n",
       "7   23  Adult"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages['group'] = pd.cut(ages['age'],bins=[0, 12, 20, 99], labels=['Child', 'Teen', 'Adult'])\n",
    "ages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "Check the [cut](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html) method\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "ages['group'] = pd.cut(x = ages['age'], bins=[12,20,25], labels=['teen', 'adult'])\n",
    "ages\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to check out the difference in performance between raw and standardized data. You will be using breast cancer data. Run the code below to import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train an SVM, cross validate and check accuracy.  \n",
    "Notes: \n",
    "- we will study cross validation in more depth in challenge 2 (the next one)\n",
    "- we will study SVM in more depth in challenges 4, 5 and 6. You can think of it as a classifier for now, and use the typical scikit models' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\Le Wagon 1\\\\AppData\\\\Local\\\\Continuum\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17070"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9191590086326928"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "model = svm.LinearSVC()\n",
    "model.fit(X,y)\n",
    "scores = cross_val_score(model, X, y)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "    \n",
    "Check out the [`cross_val_score`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) documentation for cross validating.\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "model = svm.SVC()\n",
    "scores = cross_val_score(model, X, y, cv=3)\n",
    "scores.mean()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use StandardScaler to standardize the data before training an SVM. Cross validate and check accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
      " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
      " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
      " 2.86605923e+00 4.03370791e+01 7.04097891e-03 2.54781388e-02\n",
      " 3.18937163e-02 1.17961371e-02 2.05422988e-02 3.79490387e-03\n",
      " 1.62691898e+01 2.56772232e+01 1.07261213e+02 8.80583128e+02\n",
      " 1.32368594e-01 2.54265044e-01 2.72188483e-01 1.14606223e-01\n",
      " 2.90075571e-01 8.39458172e-02]\n",
      "[[ -3.70076966  -4.97130967  -3.73591408 ...  33.21636394  39.80624701\n",
      "  102.6893221 ]\n",
      " [ -3.49265638  -4.57112333  -3.71877809 ...  14.80753207  -8.6383861\n",
      "   10.93044688]\n",
      " [ -3.56364075  -4.38267293  -3.72369832 ...  28.02294034  13.94817164\n",
      "    6.50833241]\n",
      " ...\n",
      " [ -3.81289271  -4.01281194  -3.76051525 ...   4.55979443 -22.56196515\n",
      "  -22.29682989]\n",
      " [ -3.49023646  -3.94512142  -3.70656233 ...  33.12362423  26.3537665\n",
      "  118.35097751]\n",
      " [ -4.52596303  -4.20451148  -3.86295793 ... -28.31643177  -5.47155703\n",
      "  -46.28065905]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9631021999443052"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "print(scaler.fit(X))\n",
    "print(scaler.mean_)\n",
    "X=scaler.transform(X)\n",
    "print(scaler.transform(X))\n",
    "\n",
    "model2 = svm.LinearSVC()\n",
    "model2.fit(X,y)\n",
    "scores = cross_val_score(model2, X, y)\n",
    "\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "model = svm.SVC()\n",
    "scores = cross_val_score(model, X_scaled, y, cv=3)\n",
    "scores.mean()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a model of 90+% accuracy with the data below. It has a number of irregularities that need to be dealt with prior to training. This section is not guided on purpose. Not because we are mean, but because you now have all the tools to do it on your own 💪 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>13.69</td>\n",
       "      <td>3.26</td>\n",
       "      <td>2.54</td>\n",
       "      <td>20.0</td>\n",
       "      <td>107</td>\n",
       "      <td>1.83</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.82</td>\n",
       "      <td>680</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>12.85</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2.58</td>\n",
       "      <td>22.0</td>\n",
       "      <td>106</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.96</td>\n",
       "      <td>5.58</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2.11</td>\n",
       "      <td>570</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>12.96</td>\n",
       "      <td>3.45</td>\n",
       "      <td>777.00</td>\n",
       "      <td>18.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.94</td>\n",
       "      <td>5.28</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.75</td>\n",
       "      <td>675</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>13.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2.30</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1.03</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.68</td>\n",
       "      <td>615</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>31.33</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.26</td>\n",
       "      <td>22.5</td>\n",
       "      <td>88</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>15.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.75</td>\n",
       "      <td>520</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1       2     3    4     5     6     7      8      9    10  \\\n",
       "0    14.23  1.71    2.43  15.6  127  2.80  3.06  0.28   2.29   5.64  1.04   \n",
       "1    13.20  1.78    2.14  11.2  100  2.65  2.76  0.26   1.28   4.38  1.05   \n",
       "2    13.16  2.36    2.67  18.6  101  2.80  3.24  0.30   2.81   5.68  1.03   \n",
       "3    14.37  1.95    2.50  16.8  113  3.85  3.49  0.24   2.18   7.80  0.86   \n",
       "4    13.24  2.59    2.87  21.0  118  2.80  2.69  0.39   1.82   4.32  1.04   \n",
       "..     ...   ...     ...   ...  ...   ...   ...   ...    ...    ...   ...   \n",
       "161  13.69  3.26    2.54  20.0  107  1.83  0.56  0.50   0.80   5.88  0.96   \n",
       "162  12.85  3.27    2.58  22.0  106  1.65  0.60  0.60   0.96   5.58  0.87   \n",
       "163  12.96  3.45  777.00  18.5  106  1.39  0.70  0.40   0.94   5.28  0.68   \n",
       "164  13.78  2.76    2.30  22.0   15  1.35  0.68  0.41   1.03   9.58  0.70   \n",
       "165  31.33  4.36    2.26  22.5   88  1.28  0.47  0.52  15.00  55.00  5.00   \n",
       "\n",
       "       11    12 target  \n",
       "0    3.92  1065      a  \n",
       "1    3.40  1050      a  \n",
       "2    3.17  1185      a  \n",
       "3    3.45  1480      a  \n",
       "4    2.93   735      a  \n",
       "..    ...   ...    ...  \n",
       "161  1.82   680      c  \n",
       "162  2.11   570      c  \n",
       "163  1.75   675      c  \n",
       "164  1.68   615      c  \n",
       "165  1.75   520      c  \n",
       "\n",
       "[166 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/data.csv\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b    71\n",
       "a    59\n",
       "c    36\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>13.603373</td>\n",
       "      <td>2.455422</td>\n",
       "      <td>168.933735</td>\n",
       "      <td>19.824096</td>\n",
       "      <td>97.969880</td>\n",
       "      <td>66.721566</td>\n",
       "      <td>140.655000</td>\n",
       "      <td>0.839518</td>\n",
       "      <td>1.800060</td>\n",
       "      <td>11.615181</td>\n",
       "      <td>1.004072</td>\n",
       "      <td>9.366145</td>\n",
       "      <td>1393.608434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>6.943012</td>\n",
       "      <td>2.224133</td>\n",
       "      <td>2072.581309</td>\n",
       "      <td>8.003819</td>\n",
       "      <td>18.875485</td>\n",
       "      <td>777.353917</td>\n",
       "      <td>1784.982434</td>\n",
       "      <td>6.029905</td>\n",
       "      <td>1.734921</td>\n",
       "      <td>85.958990</td>\n",
       "      <td>0.382150</td>\n",
       "      <td>77.873490</td>\n",
       "      <td>7740.327755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>12.332500</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>2.202500</td>\n",
       "      <td>17.025000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.835000</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>1.252500</td>\n",
       "      <td>3.050000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>2.142500</td>\n",
       "      <td>495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.435000</td>\n",
       "      <td>2.245000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.620000</td>\n",
       "      <td>4.475000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>2.835000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>13.687500</td>\n",
       "      <td>2.982500</td>\n",
       "      <td>2.575000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.850000</td>\n",
       "      <td>2.907500</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>1.977500</td>\n",
       "      <td>5.737500</td>\n",
       "      <td>1.127500</td>\n",
       "      <td>3.197500</td>\n",
       "      <td>1031.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>99.990000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26700.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>23000.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1111.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1             2           3           4  \\\n",
       "count  166.000000  166.000000    166.000000  166.000000  166.000000   \n",
       "mean    13.603373    2.455422    168.933735   19.824096   97.969880   \n",
       "std      6.943012    2.224133   2072.581309    8.003819   18.875485   \n",
       "min     11.030000    0.740000      0.100000    0.200000    3.000000   \n",
       "25%     12.332500    1.540000      2.202500   17.025000   88.000000   \n",
       "50%     13.010000    1.810000      2.360000   19.000000   98.000000   \n",
       "75%     13.687500    2.982500      2.575000   21.500000  107.000000   \n",
       "max     99.990000   25.000000  26700.000000  111.000000  162.000000   \n",
       "\n",
       "                  5             6           7           8            9  \\\n",
       "count    166.000000    166.000000  166.000000  166.000000   166.000000   \n",
       "mean      66.721566    140.655000    0.839518    1.800060    11.615181   \n",
       "std      777.353917   1784.982434    6.029905    1.734921    85.958990   \n",
       "min        0.980000      0.100000    0.130000    0.410000     0.110000   \n",
       "25%        1.835000      1.330000    0.260000    1.252500     3.050000   \n",
       "50%        2.435000      2.245000    0.320000    1.620000     4.475000   \n",
       "75%        2.850000      2.907500    0.430000    1.977500     5.737500   \n",
       "max    10000.000000  23000.000000   78.000000   18.000000  1111.000000   \n",
       "\n",
       "               10           11            12  \n",
       "count  166.000000   166.000000    166.000000  \n",
       "mean     1.004072     9.366145   1393.608434  \n",
       "std      0.382150    77.873490   7740.327755  \n",
       "min      0.480000     0.230000     10.000000  \n",
       "25%      0.860000     2.142500    495.000000  \n",
       "50%      1.005000     2.835000    660.000000  \n",
       "75%      1.127500     3.197500   1031.250000  \n",
       "max      5.000000  1000.000000  99999.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b0d6f7f5c8>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.index.values, data['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Balancing\n",
    "count_class_b, count_class_a, count_class_c = data['target'].value_counts()\n",
    "count_class_b\n",
    "count_class_a\n",
    "count_class_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy import stats\n",
    "#df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "\n",
    "le_target = LabelEncoder()\n",
    "y = le_target.fit_transform(data['target'])\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nettoyage et scaling\n",
    "\n",
    "X = data.iloc[:,0:13]\n",
    "\n",
    "# Scale X\n",
    "rscaler = RobustScaler()\n",
    "rscaler.fit(X)\n",
    "Xscaled = rscaler.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Le Wagon 1\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8671636477557529"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create model\n",
    "\n",
    "# TRAIN MODEL\n",
    "model = svm.SVC(C=3)\n",
    "scores = cross_val_score(model, Xscaled, y,  cv=8)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "\n",
    "Follow these steps: \n",
    "- Balance the dataset\n",
    "- Encode target\n",
    "- Scale for outliers\n",
    "- Train model\n",
    "\n",
    "</details>\n",
    "<details>\n",
    "  <summary>View solution</summary>\n",
    "\n",
    "```python\n",
    "#BALANCING THE DATASET\n",
    "\n",
    "# Section data according to target\n",
    "data_target_a = data[data['target'] == \"a\"]\n",
    "data_target_b = data[data['target'] == \"b\"]\n",
    "data_target_c = data[data['target'] == \"c\"]\n",
    "\n",
    "# Count occurences of each target\n",
    "count_target_a = data_target_a.target.value_counts()\n",
    "count_target_b = data_target_b.target.value_counts()\n",
    "count_target_c = data_target_c.target.value_counts()\n",
    "\n",
    "print(count_target_a)\n",
    "print(count_target_b)\n",
    "print(count_target_c)\n",
    "\n",
    "# Undersample the majoriti class\n",
    "data_target_b_under = data_target_b.sample(count_target_a.item())\n",
    "\n",
    "# Oversample the minority class\n",
    "data_target_c_over = data_target_c.sample(count_target_a.item(), replace = True)\n",
    "\n",
    "# Concatenate balanced data\n",
    "data_balanced = pd.concat([data_target_c_over,data_target_b_under, data_target_a], axis=0)\n",
    "\n",
    "# Visualize balanced data target counts\n",
    "data_balanced.target.value_counts()\n",
    "\n",
    "\n",
    "# ENCODING TARGET\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(data_balanced['target'])\n",
    "print(y)\n",
    "\n",
    "# SCALING FOR OUTLIERS\n",
    "\n",
    "# Make X\n",
    "X = data_balanced.iloc[:,0:13]\n",
    "\n",
    "# Scale X\n",
    "r_scaler = RobustScaler()\n",
    "r_scaler.fit(X)\n",
    "scaled_data = r_scaler.transform(X)\n",
    "\n",
    "\n",
    "# TRAIN MODEL\n",
    "model = svm.SVC()\n",
    "scores = cross_val_score(model, scaled_data, y, cv=5)\n",
    "scores.mean()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
